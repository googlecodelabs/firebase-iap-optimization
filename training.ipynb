{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow.lite as tflite\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, concatenate, Input, Embedding\n",
    "from tensorflow.keras.layers import Reshape, Concatenate, BatchNormalization, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import glob\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import plotly\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "client=storage.Client()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 1, validation files: 1, test files: 1\n"
     ]
    }
   ],
   "source": [
    "# TODO: REPLACE WITH YOUR OWN FILE. \n",
    "# This example demonstrates how to use files from GCS. You can use local files as well.\n",
    "\n",
    "# Get file lists from GCS\n",
    "training_files = list(filter(lambda s: '.csv' in s, [blob.name for blob in client.list_blobs('iap-optimization-codelab', prefix='training-data', )]))\n",
    "validation_files = list(filter(lambda s: '.csv' in s, [blob.name for blob in client.list_blobs('iap-optimization-codelab', prefix='validation-data', )]))\n",
    "test_files = list(filter(lambda s: '.csv' in s, [blob.name for blob in client.list_blobs('iap-optimization-codelab', prefix='test-data', )]))\n",
    "\n",
    "\n",
    "# Add full path to it\n",
    "training_files = ['gs://iap-optimization-codelab/' + f for f in training_files]\n",
    "validation_files = ['gs://iap-optimization-codelab/' + f for f in validation_files]\n",
    "test_files = ['gs://iap-optimization-codelab/' + f for f in test_files]\n",
    "\n",
    "print(\"Training files: {}, validation files: {}, test files: {}\".format(len(training_files), len(validation_files), len(test_files)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns.\n",
    "CAT_COLUMNS = [\n",
    " 'geo_country', \n",
    " 'device_os',\n",
    " 'last_run_end_reason',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample data to initialize scaler and actions mapping\n",
    "\n",
    "We need to understand the data so we can prepare it for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading gs://iap-optimization-codelab/training-data/training.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_avg</th>\n",
       "      <th>coins_spent</th>\n",
       "      <th>game_day</th>\n",
       "      <th>geo_country</th>\n",
       "      <th>device_os</th>\n",
       "      <th>last_run_end_reason</th>\n",
       "      <th>presented_powerup</th>\n",
       "      <th>is_powerup_clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>670</td>\n",
       "      <td>29</td>\n",
       "      <td>China</td>\n",
       "      <td>Android</td>\n",
       "      <td>wall</td>\n",
       "      <td>parachute</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135</td>\n",
       "      <td>526</td>\n",
       "      <td>127</td>\n",
       "      <td>UK</td>\n",
       "      <td>iOS</td>\n",
       "      <td>wall</td>\n",
       "      <td>extra_life</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>iOS</td>\n",
       "      <td>laser</td>\n",
       "      <td>time_machine</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>470</td>\n",
       "      <td>102</td>\n",
       "      <td>Russia</td>\n",
       "      <td>iOS</td>\n",
       "      <td>laser</td>\n",
       "      <td>head_start</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174</td>\n",
       "      <td>1010</td>\n",
       "      <td>49</td>\n",
       "      <td>China</td>\n",
       "      <td>Android</td>\n",
       "      <td>laser</td>\n",
       "      <td>sparky_armor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699996</th>\n",
       "      <td>103</td>\n",
       "      <td>1375</td>\n",
       "      <td>268</td>\n",
       "      <td>US</td>\n",
       "      <td>Android</td>\n",
       "      <td>wall</td>\n",
       "      <td>extra_life</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699997</th>\n",
       "      <td>81</td>\n",
       "      <td>1401</td>\n",
       "      <td>53</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>Android</td>\n",
       "      <td>laser</td>\n",
       "      <td>nuclear_missle</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699998</th>\n",
       "      <td>24</td>\n",
       "      <td>894</td>\n",
       "      <td>158</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Android</td>\n",
       "      <td>wall</td>\n",
       "      <td>nuclear_missle</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699999</th>\n",
       "      <td>102</td>\n",
       "      <td>3043</td>\n",
       "      <td>162</td>\n",
       "      <td>Italy</td>\n",
       "      <td>iOS</td>\n",
       "      <td>wall</td>\n",
       "      <td>head_start</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700000</th>\n",
       "      <td>101</td>\n",
       "      <td>170</td>\n",
       "      <td>98</td>\n",
       "      <td>France</td>\n",
       "      <td>iOS</td>\n",
       "      <td>laser</td>\n",
       "      <td>coin_magnet</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700001 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_avg  coins_spent  game_day  geo_country device_os  \\\n",
       "0                194          670        29        China   Android   \n",
       "1                135          526       127           UK       iOS   \n",
       "2                 85         1515         0           UK       iOS   \n",
       "3                 60          470       102       Russia       iOS   \n",
       "4                174         1010        49        China   Android   \n",
       "...              ...          ...       ...          ...       ...   \n",
       "699996           103         1375       268           US   Android   \n",
       "699997            81         1401        53  South Korea   Android   \n",
       "699998            24          894       158       Russia   Android   \n",
       "699999           102         3043       162        Italy       iOS   \n",
       "700000           101          170        98       France       iOS   \n",
       "\n",
       "       last_run_end_reason presented_powerup  is_powerup_clicked  \n",
       "0                     wall         parachute               False  \n",
       "1                     wall        extra_life                True  \n",
       "2                    laser      time_machine               False  \n",
       "3                    laser        head_start               False  \n",
       "4                    laser      sparky_armor                True  \n",
       "...                    ...               ...                 ...  \n",
       "699996                wall        extra_life               False  \n",
       "699997               laser    nuclear_missle               False  \n",
       "699998                wall    nuclear_missle               False  \n",
       "699999                wall        head_start               False  \n",
       "700000               laser       coin_magnet               False  \n",
       "\n",
       "[700001 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_files_into_df(file_list):\n",
    "    li = []\n",
    "    for filename in file_list:\n",
    "        print(\"reading {}\".format(filename))\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df.sample(frac=1) # Shuffle\n",
    "        li.append(df)\n",
    "    return pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "sample_data = read_files_into_df(training_files)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geo_country': ['geo_country_Canada',\n",
       "  'geo_country_China',\n",
       "  'geo_country_France',\n",
       "  'geo_country_Germany',\n",
       "  'geo_country_India',\n",
       "  'geo_country_Italy',\n",
       "  'geo_country_Japan',\n",
       "  'geo_country_Russia',\n",
       "  'geo_country_South Korea',\n",
       "  'geo_country_UK',\n",
       "  'geo_country_US'],\n",
       " 'device_os': ['device_os_Android', 'device_os_iOS'],\n",
       " 'last_run_end_reason': ['last_run_end_reason_laser',\n",
       "  'last_run_end_reason_wall']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go through all data to determine the category space for each column.\n",
    "category_space_mapping = {}\n",
    "for c in CAT_COLUMNS:\n",
    "    category_space_mapping[c] = list(map(lambda v: c+'_'+str(v), list(sample_data[c].astype('category').cat.categories)))\n",
    "\n",
    "category_space_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df, cols):\n",
    "  \"\"\"Returns one-hot encoding of DataFrame df including columns in cols.\"\"\"\n",
    "  for col in cols:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "    dummies = dummies.T.reindex(category_space_mapping[col]).T.fillna(0)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop(col, axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess a dataframe read from CSV into state action reward triples that can be used in model training.\n",
    "def pre_process(df):\n",
    "    # List of all numerical columns\n",
    "    numerical_columns = list(filter(lambda x: x not in (CAT_COLUMNS + ['is_powerup_clicked', 'presented_powerup']), df.columns.values.tolist()))\n",
    "\n",
    "    # Drop row if action or reward is na\n",
    "    df = df[df['presented_powerup'].notna()]\n",
    "    \n",
    "    # Find all NAs \n",
    "    nans = df.isna().sum()\n",
    "    nans= nans[nans!=0]\n",
    "    columns_needs_filling = nans.index.tolist()\n",
    "\n",
    "    # Determine which columns to fill\n",
    "    numerical_columns_to_fill = list(set(columns_needs_filling) & set(numerical_columns))\n",
    "    cat_columns_to_fill = list(set(columns_needs_filling) & set(CAT_COLUMNS))\n",
    "\n",
    "    # Fill NAs\n",
    "    df[cat_columns_to_fill] = df[cat_columns_to_fill].fillna(method='bfill').fillna(method='ffill')\n",
    "    df[numerical_columns_to_fill] = df[numerical_columns_to_fill].fillna(value=0)\n",
    "\n",
    "    # Verify all NA is filled\n",
    "    assert df.isna().sum().sum() == 0\n",
    "    \n",
    "    # actions for on all data\n",
    "    actions = df['presented_powerup'].astype('category').cat.codes\n",
    "    # action space - list of all actions to choose from\n",
    "    action_space = df['presented_powerup'].astype('category').cat.categories\n",
    "    # mapping from category code back to string\n",
    "    actions_mapping = dict(enumerate(df['presented_powerup'].astype('category').cat.categories))\n",
    "    \n",
    "    rewards = df['is_powerup_clicked']\n",
    "    states = df.drop(['presented_powerup', 'is_powerup_clicked'], axis=1)\n",
    "    \n",
    "    states = one_hot(states, CAT_COLUMNS)\n",
    "    \n",
    "    # Assert all categorical state has been found from previously established mapping\n",
    "    assert states.isna().sum().sum() == 0\n",
    "    \n",
    "    return (states, actions, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_states, sample_actions, sample_rewards = pre_process(sample_data)\n",
    "\n",
    "# List of all numerical columns\n",
    "NUM_COLUMNS = list(filter(lambda x: x not in (CAT_COLUMNS + ['is_powerup_clicked', 'presented_powerup']), sample_data.columns.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_avg</th>\n",
       "      <th>coins_spent</th>\n",
       "      <th>game_day</th>\n",
       "      <th>geo_country_Canada</th>\n",
       "      <th>geo_country_China</th>\n",
       "      <th>geo_country_France</th>\n",
       "      <th>geo_country_Germany</th>\n",
       "      <th>geo_country_India</th>\n",
       "      <th>geo_country_Italy</th>\n",
       "      <th>geo_country_Japan</th>\n",
       "      <th>geo_country_Russia</th>\n",
       "      <th>geo_country_South Korea</th>\n",
       "      <th>geo_country_UK</th>\n",
       "      <th>geo_country_US</th>\n",
       "      <th>device_os_Android</th>\n",
       "      <th>device_os_iOS</th>\n",
       "      <th>last_run_end_reason_laser</th>\n",
       "      <th>last_run_end_reason_wall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>670</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135</td>\n",
       "      <td>526</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85</td>\n",
       "      <td>1515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>470</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174</td>\n",
       "      <td>1010</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699996</th>\n",
       "      <td>103</td>\n",
       "      <td>1375</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699997</th>\n",
       "      <td>81</td>\n",
       "      <td>1401</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699998</th>\n",
       "      <td>24</td>\n",
       "      <td>894</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699999</th>\n",
       "      <td>102</td>\n",
       "      <td>3043</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700000</th>\n",
       "      <td>101</td>\n",
       "      <td>170</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700001 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_avg  coins_spent  game_day  geo_country_Canada  \\\n",
       "0                194          670        29                   0   \n",
       "1                135          526       127                   0   \n",
       "2                 85         1515         0                   0   \n",
       "3                 60          470       102                   0   \n",
       "4                174         1010        49                   0   \n",
       "...              ...          ...       ...                 ...   \n",
       "699996           103         1375       268                   0   \n",
       "699997            81         1401        53                   0   \n",
       "699998            24          894       158                   0   \n",
       "699999           102         3043       162                   0   \n",
       "700000           101          170        98                   0   \n",
       "\n",
       "        geo_country_China  geo_country_France  geo_country_Germany  \\\n",
       "0                       1                   0                    0   \n",
       "1                       0                   0                    0   \n",
       "2                       0                   0                    0   \n",
       "3                       0                   0                    0   \n",
       "4                       1                   0                    0   \n",
       "...                   ...                 ...                  ...   \n",
       "699996                  0                   0                    0   \n",
       "699997                  0                   0                    0   \n",
       "699998                  0                   0                    0   \n",
       "699999                  0                   0                    0   \n",
       "700000                  0                   1                    0   \n",
       "\n",
       "        geo_country_India  geo_country_Italy  geo_country_Japan  \\\n",
       "0                       0                  0                  0   \n",
       "1                       0                  0                  0   \n",
       "2                       0                  0                  0   \n",
       "3                       0                  0                  0   \n",
       "4                       0                  0                  0   \n",
       "...                   ...                ...                ...   \n",
       "699996                  0                  0                  0   \n",
       "699997                  0                  0                  0   \n",
       "699998                  0                  0                  0   \n",
       "699999                  0                  1                  0   \n",
       "700000                  0                  0                  0   \n",
       "\n",
       "        geo_country_Russia  geo_country_South Korea  geo_country_UK  \\\n",
       "0                        0                        0               0   \n",
       "1                        0                        0               1   \n",
       "2                        0                        0               1   \n",
       "3                        1                        0               0   \n",
       "4                        0                        0               0   \n",
       "...                    ...                      ...             ...   \n",
       "699996                   0                        0               0   \n",
       "699997                   0                        1               0   \n",
       "699998                   1                        0               0   \n",
       "699999                   0                        0               0   \n",
       "700000                   0                        0               0   \n",
       "\n",
       "        geo_country_US  device_os_Android  device_os_iOS  \\\n",
       "0                    0                  1              0   \n",
       "1                    0                  0              1   \n",
       "2                    0                  0              1   \n",
       "3                    0                  0              1   \n",
       "4                    0                  1              0   \n",
       "...                ...                ...            ...   \n",
       "699996               1                  1              0   \n",
       "699997               0                  1              0   \n",
       "699998               0                  1              0   \n",
       "699999               0                  0              1   \n",
       "700000               0                  0              1   \n",
       "\n",
       "        last_run_end_reason_laser  last_run_end_reason_wall  \n",
       "0                               0                         1  \n",
       "1                               0                         1  \n",
       "2                               1                         0  \n",
       "3                               1                         0  \n",
       "4                               1                         0  \n",
       "...                           ...                       ...  \n",
       "699996                          0                         1  \n",
       "699997                          1                         0  \n",
       "699998                          0                         1  \n",
       "699999                          0                         1  \n",
       "700000                          1                         0  \n",
       "\n",
       "[700001 rows x 18 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SIZE = sample_states.shape[1]\n",
    "ACTION_SPACE = sample_data['presented_powerup'].astype('category').cat.categories\n",
    "ACTIONS_MAPPING = dict(enumerate(sample_data['presented_powerup'].astype('category').cat.categories))\n",
    "ACTION_SPACE_SIZE = len(ACTION_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scikit-learn scaler object to scale the states\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(sample_states[NUM_COLUMNS])\n",
    "\n",
    "def scale_transform(df):\n",
    "    df[NUM_COLUMNS] = scaler.transform(df[NUM_COLUMNS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sample weight based on frequency of reward showing up.\n",
    "actions_distribution = sample_data['presented_powerup'].value_counts(normalize=True)\n",
    "\n",
    "# Sample with reward of 1 is 2x the weight of those with reward of 0.\n",
    "# This is decided based on the distribution of rewards.\n",
    "# Then the samples with reward of 1 is scaled based on their distribution.\n",
    "actions_weight = dict((2/actions_distribution) ** 0.5)\n",
    "\n",
    "# Sample weight is 1 if reward is 0. Otherwise it's weighted by action's distribution frequency\n",
    "def get_sample_weight(rewards, actions):\n",
    "    weight_from_action = actions.map(lambda a: actions_weight[ACTIONS_MAPPING[a]])\n",
    "    weight = weight_from_action.combine(rewards, (lambda w_a, r : 1 if r == 0 else w_a))\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom callback to evaluate model\n",
    "\n",
    "After each epoch, we will test our model against validation data to see how it's performing relative to the benchmark. We will use random selection of actions as the benchmark.\n",
    "\n",
    "To test our data, we will first **filter for the samples that yield a positive reward**, and **see if our model can predict the action that generated that positive reward**.\n",
    "\n",
    "Because our dataset might be biased (one action appearing more frequently than others), we need to **downsample all actions so they are evenly distributed**, otherwise the test result will be biased. For example, if `action_1` is appears twice as frequently as the other actions, a model that only predicts `action_1` will be \"twice as good as the benchmark\", where in reality this will not be true.\n",
    "\n",
    "![downsample_diagram](./graphics/downsample_test_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax to convert model prediction to action index.\n",
    "def get_action(model_prediction):\n",
    "    return np.argmax(model_prediction)\n",
    "\n",
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_data = read_files_into_df(validation_files)\n",
    "        test_states, test_actions, test_rewards = pre_process(test_data)\n",
    "        scale_transform(test_states)\n",
    "        \n",
    "        test_actions.rename('action', inplace=True)\n",
    "        test_data = pd.concat([test_states, test_actions, test_rewards], axis=1)\n",
    "\n",
    "        # Filter only the ones clicked on\n",
    "        positive_test_data = test_data[test_data['is_powerup_clicked']==1]\n",
    "        # Find the count of the action with the smallest sample size\n",
    "        down_sample_size = positive_test_data.groupby('action').count()['is_powerup_clicked'].min()\n",
    "        # Downsample\n",
    "        down_sampled_positive_test_data = positive_test_data.groupby('action').apply(lambda x: x.sample(down_sample_size))\n",
    "\n",
    "        # Now we have the test dataset ready, run it through the model\n",
    "        prediction_result = self.model.predict({\n",
    "            'states': tf.convert_to_tensor(down_sampled_positive_test_data.iloc[:, :-2].values)\n",
    "        })\n",
    "        prediction_result = np.array(list(map(get_action, prediction_result)))\n",
    "\n",
    "        # Construct all result into dataframe\n",
    "        test_df = pd.DataFrame({'pred':prediction_result, 'real': down_sampled_positive_test_data['action']})\n",
    "        test_df['is_match'] = test_df['pred'] == test_df['real']\n",
    "\n",
    "        # Count number of matches\n",
    "        test_counts = test_df['is_match'].value_counts()\n",
    "\n",
    "        # Compute benchmark by randomly selecting across 8 actions\n",
    "        benchmarking_result = test_counts.append(pd.Series([test_df.shape[0] / ACTION_SPACE_SIZE], index=['benchmark']))\n",
    "        print(\"Model performance comparing to random: {}\".format(benchmarking_result[1]/benchmarking_result[2]))\n",
    "\n",
    "        # Log the distribution of all actions\n",
    "        test_action_count = test_df['pred'].value_counts()\n",
    "        \n",
    "        log_for_current_epoch = {}\n",
    "        \n",
    "        for i in range(ACTION_SPACE_SIZE):\n",
    "            log_for_current_epoch = {\n",
    "                **log_for_current_epoch,\n",
    "                ('action {}'.format(i)): test_action_count.get(i, 0),\n",
    "            }\n",
    "        optimizer = self.model.optimizer\n",
    "        \n",
    "        # To calculate statistical significance of the improvements,\n",
    "        # try using the Binomial distribution calculator:\n",
    "        # https://www.socscistatistics.com/tests/binomial/default2.aspx\n",
    "        wandb.log({\n",
    "            **log_for_current_epoch,\n",
    "            'False prediction': benchmarking_result[0],\n",
    "            'Correct prediction': benchmarking_result[1],\n",
    "            'Benchmark': benchmarking_result[2],\n",
    "                  })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 2048\n",
    "\n",
    "def train_generator():\n",
    "    batch_size = TRAIN_BATCH_SIZE\n",
    "    for filename in training_files * 100:\n",
    "        print(\"reading {}\".format(filename))\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        df.sample(frac=1) # Shuffle\n",
    "        states, actions, rewards = pre_process(df)\n",
    "        scale_transform(states)\n",
    "        i = 0\n",
    "        while i * batch_size < states.shape[0]:\n",
    "            s = states[i * batch_size : (i + 1) * batch_size]\n",
    "            a = actions[i * batch_size : (i + 1) * batch_size]\n",
    "            r = rewards[i * batch_size : (i + 1) * batch_size]\n",
    "            yield ({ 'states': tf.convert_to_tensor(s.values), 'actions': tf.convert_to_tensor(a.values)},\n",
    "                   tf.convert_to_tensor(r.values),\n",
    "                   tf.convert_to_tensor(get_sample_weight(r, a))\n",
    "                  )\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "### Loss computation\n",
    "The loss computation for our model is slightly different from how it's computed in a classification model.\n",
    "\n",
    "Say performing action `a3` given state `s`, gives the reward `r` of `1.0`. This can only tells us `a3` is a good option, but it doesn't tell us anything about the other actions. Therefore, we can only learn about action `a3`.\n",
    "\n",
    "Putting this in the code means **only the output node for `a3` will have a non-zero loss**.\n",
    "\n",
    "![loss computation](./graphics/loss_compuation_diagram.png)\n",
    "\n",
    "To achieve this with keras, we subclassed `keras.Model` and wrote a customized `train_step` to use as a wrapper of our `keras.Sequential` model, for further details about this, you can read this tutorial [here](https://keras.io/guides/customizing_what_happens_in_fit/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralBanditModel(keras.Model):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(NeuralBanditModel, self).__init__()\n",
    "        self.nn = tf.keras.Sequential(\n",
    "            [\n",
    "                Input(shape=(input_dim,)),\n",
    "                Dense(256, activation='relu'),\n",
    "                Dense(512, activation='relu'),\n",
    "                Dense(512, activation='relu'),\n",
    "                Dense(256, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(128, activation='relu'),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.2),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dense(output_dim, activation='relu'),\n",
    "            ],\n",
    "            name=\"neural_greedy\",\n",
    "        )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.nn(inputs['states'])\n",
    "    \n",
    "    # Override train_step to allow custom training logic\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y, sample_weight = data\n",
    "        \n",
    "        states = x['states']\n",
    "        actions = x['actions']\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "\n",
    "            # Start target from prediction result\n",
    "            target = y_pred.numpy()\n",
    "            # Find the ones that are affected by the actions and update them accordingly\n",
    "            target[np.arange(states.shape[0]), actions] = y\n",
    "            # Convert back to tensor\n",
    "            target_tensor = tf.convert_to_tensor(target)\n",
    "            \n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compiled_loss(target_tensor, y_pred, regularization_losses=self.losses, sample_weight=sample_weight,)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(loss, self.nn.trainable_weights)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.nn.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.compiled_metrics.update_state(target_tensor, y_pred)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        \n",
    "        states = x['states']\n",
    "        actions = x['actions']\n",
    "        \n",
    "        y_pred = self(x, training=True)  # Forward pass\n",
    "\n",
    "        # Start target from prediction result\n",
    "        target = y_pred.numpy()\n",
    "        # Find the ones that are affected by the actions and update them accordingly\n",
    "        target[np.arange(states.shape[0]), actions] = y\n",
    "        # Convert back to tensor\n",
    "        target_tensor = tf.convert_to_tensor(target)\n",
    "        \n",
    "        self.compiled_loss(target_tensor, y_pred, regularization_losses=self.losses)\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(target_tensor, y_pred)\n",
    "        \n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/lihes/iap-optimization-codelab\" target=\"_blank\">https://app.wandb.ai/lihes/iap-optimization-codelab</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/lihes/iap-optimization-codelab/runs/1gwrtlv7\" target=\"_blank\">https://app.wandb.ai/lihes/iap-optimization-codelab/runs/1gwrtlv7</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.26 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starts\n",
      "reading gs://iap-optimization-codelab/training-data/training.csv\n",
      "WARNING:tensorflow:Layer neural_bandit_model_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer neural_bandit_model_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0565reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2419174102510895\n",
      "256/256 [==============================] - 57s 223ms/step - loss: 0.0565\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0430reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2719651379954346\n",
      "256/256 [==============================] - 55s 216ms/step - loss: 0.0430\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0423reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2664038182195476\n",
      "256/256 [==============================] - 55s 216ms/step - loss: 0.0423\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0420reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2797675866362317\n",
      "256/256 [==============================] - 56s 220ms/step - loss: 0.0420\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0417reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2809296534550736\n",
      "256/256 [==============================] - 56s 217ms/step - loss: 0.0417\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0413reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2656152728781904\n",
      "256/256 [==============================] - 56s 221ms/step - loss: 0.0413\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0415reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.3057480805146295\n",
      "256/256 [==============================] - 55s 216ms/step - loss: 0.0415\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0413reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2481427682091721\n",
      "256/256 [==============================] - 55s 215ms/step - loss: 0.0413\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0411reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.266694334924258\n",
      "256/256 [==============================] - 57s 221ms/step - loss: 0.0411\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.0410reading gs://iap-optimization-codelab/validation-data/validation.csv\n",
      "Model performance comparing to random: 1.2871965137995436\n",
      "256/256 [==============================] - 55s 214ms/step - loss: 0.0410\n"
     ]
    }
   ],
   "source": [
    "# TODO: (Optional) Replace with your own project ID on https://wandb.ai\n",
    "# Alternatively you can remove wandb logging.\n",
    "wandb.init(project=\"iap-optimization-codelab\")\n",
    "\n",
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = 256\n",
    "\n",
    "initial_learning_rate = 0.0002\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "model = NeuralBanditModel(STATE_SIZE, ACTION_SPACE.shape[0])\n",
    "model.compile(optimizer=Adam(learning_rate = lr_schedule), \n",
    "              loss=\"mse\", \n",
    "              run_eagerly=True)\n",
    "\n",
    "wandb.config.update({\"n_train\": EPOCHS * STEPS_PER_EPOCH * TRAIN_BATCH_SIZE, \n",
    "                     \"batch_size\": TRAIN_BATCH_SIZE,\n",
    "                     \"epochs\": EPOCHS,\n",
    "                     \"activation\": 'relu',\n",
    "                     'learning_rate': tf.keras.optimizers.schedules.serialize(lr_schedule),\n",
    "                     'architecture': list(map(lambda l : l.get_output_at(0).get_shape().as_list(), model.nn.layers))\n",
    "                    })\n",
    "\n",
    "print(\"Training starts\")\n",
    "history = model.fit(x=train_generator(),\n",
    "                    verbose=1, \n",
    "                    epochs=EPOCHS, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    shuffle=True, \n",
    "                    callbacks=[\n",
    "                        WandbCallback(),\n",
    "                        ValidationCallback(),\n",
    "                    ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "\n",
    "Use data in the test set to test the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading gs://iap-optimization-codelab/test-data/test.csv\n",
      "Model performance comparing to random: 1.2815172297011261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.26 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "def test_model():\n",
    "    test_data = read_files_into_df(test_files)\n",
    "    test_states, test_actions, test_rewards = pre_process(test_data)\n",
    "    scale_transform(test_states)\n",
    "\n",
    "    test_actions.rename('action', inplace=True)\n",
    "    test_data = pd.concat([test_states, test_actions, test_rewards], axis=1)\n",
    "\n",
    "    # Filter only the ones clicked on\n",
    "    positive_test_data = test_data[test_data['is_powerup_clicked']==1]\n",
    "    # Find the count of the action with the smallest sample size\n",
    "    down_sample_size = positive_test_data.groupby('action').count()['is_powerup_clicked'].min()\n",
    "    # Downsample\n",
    "    down_sampled_positive_test_data = positive_test_data.groupby('action').apply(lambda x: x.sample(down_sample_size))\n",
    "\n",
    "    # Now we have the test dataset ready, run it through the model\n",
    "    prediction_result = model.predict({\n",
    "        'states': tf.convert_to_tensor(down_sampled_positive_test_data.iloc[:, :-2].values)\n",
    "    })\n",
    "    prediction_result = np.array(list(map(get_action, prediction_result)))\n",
    "\n",
    "    # Construct all result into dataframe\n",
    "    test_df = pd.DataFrame({'pred':prediction_result, 'real': down_sampled_positive_test_data['action']})\n",
    "    test_df['is_match'] = test_df['pred'] == test_df['real']\n",
    "\n",
    "    # Count number of matches\n",
    "    test_counts = test_df['is_match'].value_counts()\n",
    "\n",
    "    # Compute benchmark by randomly selecting across 13 actions\n",
    "    benchmarking_result = test_counts.append(pd.Series([test_df.shape[0] / ACTION_SPACE_SIZE], index=['benchmark']))\n",
    "    print(\"Model performance comparing to random: {}\".format(benchmarking_result[1]/benchmarking_result[2]))\n",
    "\n",
    "    # Log the distribution of all actions\n",
    "    test_action_count = test_df['pred'].value_counts()\n",
    "\n",
    "    log_for_current_epoch = {}\n",
    "\n",
    "    for i in range(ACTION_SPACE_SIZE):\n",
    "        log_for_current_epoch = {\n",
    "            **log_for_current_epoch,\n",
    "            ('Test - action {}'.format(i)): test_action_count.get(i, 0),\n",
    "        }\n",
    "\n",
    "    wandb.log({\n",
    "        **log_for_current_epoch,\n",
    "        'Test - False prediction': benchmarking_result[0],\n",
    "        'Test - Correct prediction': benchmarking_result[1],\n",
    "        'Test - Benchmark': benchmarking_result[2],\n",
    "    })\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint 2021-04-14 18:27:49.853364/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint 2021-04-14 18:27:49.853364/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./model_checkpoint ' + str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxmak97qa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxmak97qa/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tflite.TFLiteConverter.from_keras_model(model.nn)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with tf.io.gfile.GFile('iap-optimizer.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting model metadata\n",
    "\n",
    "https://www.tensorflow.org/lite/convert/metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {}\n",
    "\n",
    "for i, col in enumerate(NUM_COLUMNS):\n",
    "    data[col] = {}\n",
    "    data[col]['type'] = 'numerical'\n",
    "    data[col]['mean'] = scaler.mean_[i]\n",
    "    data[col]['std'] = scaler.scale_[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"coins_spent\": {\n",
      "        \"mean\": 1012.2316639547657,\n",
      "        \"std\": 576.6266132193391,\n",
      "        \"type\": \"numerical\"\n",
      "    },\n",
      "    \"device_os\": {\n",
      "        \"all_values\": [\n",
      "            \"Android\",\n",
      "            \"iOS\"\n",
      "        ],\n",
      "        \"type\": \"categorical\"\n",
      "    },\n",
      "    \"distance_avg\": {\n",
      "        \"mean\": 99.49789786014591,\n",
      "        \"std\": 39.65095273506135,\n",
      "        \"type\": \"numerical\"\n",
      "    },\n",
      "    \"game_day\": {\n",
      "        \"mean\": 108.33904808707416,\n",
      "        \"std\": 86.79340575071703,\n",
      "        \"type\": \"numerical\"\n",
      "    },\n",
      "    \"geo_country\": {\n",
      "        \"all_values\": [\n",
      "            \"Canada\",\n",
      "            \"China\",\n",
      "            \"France\",\n",
      "            \"Germany\",\n",
      "            \"India\",\n",
      "            \"Italy\",\n",
      "            \"Japan\",\n",
      "            \"Russia\",\n",
      "            \"South Korea\",\n",
      "            \"UK\",\n",
      "            \"US\"\n",
      "        ],\n",
      "        \"type\": \"categorical\"\n",
      "    },\n",
      "    \"last_run_end_reason\": {\n",
      "        \"all_values\": [\n",
      "            \"laser\",\n",
      "            \"wall\"\n",
      "        ],\n",
      "        \"type\": \"categorical\"\n",
      "    },\n",
      "    \"output_mapping\": [\n",
      "        \"coin_magnet\",\n",
      "        \"coin_multiplier\",\n",
      "        \"extra_life\",\n",
      "        \"head_start\",\n",
      "        \"nuclear_missle\",\n",
      "        \"parachute\",\n",
      "        \"sparky_armor\",\n",
      "        \"time_machine\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for col in CAT_COLUMNS:\n",
    "    dummies = pd.get_dummies(sample_data[col], drop_first=False)    \n",
    "    data[col] = {}\n",
    "    data[col]['type'] = 'categorical'\n",
    "    data[col]['all_values'] = list(dummies.columns)\n",
    "\n",
    "data['output_mapping'] = list(ACTIONS_MAPPING.values())\n",
    "\n",
    "with open('preprocess.json', 'w') as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "print(json.dumps(data, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing metadata to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_lite_support/metadata/metadata.py:344: UserWarning: File, 'preprocess.json', does not exsit in the metadata. But packing it to tflite model is still allowed.\n",
      "  \"tflite model is still allowed.\".format(f))\n"
     ]
    }
   ],
   "source": [
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "# Creates model info.\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"IAP optimizer\"\n",
    "model_meta.description = (\"Determines the expected reward for each action given the state of a user\")\n",
    "model_meta.version = \"v1\"\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()\n",
    "\n",
    "populator = _metadata.MetadataPopulator.with_model_file('./iap-optimizer.tflite')\n",
    "populator.load_associated_files([\"./preprocess.json\"])\n",
    "populator.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on model\n",
    "\n",
    "Run inference on 10 rows to see what results we get.\n",
    "\n",
    "We will run inference again on the TF-lite model on client side for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading gs://iap-optimization-codelab/test-data/test.csv\n"
     ]
    }
   ],
   "source": [
    "raw_test_data = read_files_into_df(test_files[:1])\n",
    "test_data = raw_test_data.sample(frac=0.05) \n",
    "test_states, test_actions, test_rewards = pre_process(test_data)\n",
    "scale_transform(test_states)\n",
    "\n",
    "# Same input to the model to a csv for valiation\n",
    "test_states[:10].to_csv('model_input_samples.csv')\n",
    "test_actions.rename('action', inplace=True)\n",
    "test_data = pd.concat([test_states, test_actions, test_rewards], axis=1)\n",
    "# Now we have the test dataset ready, run it through the model\n",
    "prediction_result = model.predict({\n",
    "    'states': tf.convert_to_tensor(test_data\n",
    "                                .iloc[:, :-2].values)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build raw data and output into one CSV for validation\n",
    "s = raw_test_data[:10]\n",
    "v = pd.DataFrame(prediction_result[:10], columns=list(ACTIONS_MAPPING.values()))\n",
    "r = df_concat = pd.concat([s, v], axis=1)\n",
    "r.to_csv('./integration_validation_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
